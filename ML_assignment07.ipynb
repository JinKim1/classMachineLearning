{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_assignment07.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBUwl4gtErBATCDYzFs5gY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinKim1/classMachineLearning/blob/master/ML_assignment07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr6PRLf5lOrG",
        "colab_type": "text"
      },
      "source": [
        "Machine Learning note for Dongjin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scCLaTx3keXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "cbddc32d-32a6-4d2e-ad60-b6ffcd2ebc2a"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data    = np.genfromtxt(\"data-nonlinear.txt\", delimiter=',')\n",
        "\n",
        "x  = data[:, 0]\n",
        "y  = data[:, 1]\n",
        "l   = data[:, 2]\n",
        "\n",
        "x_0 = x[l == 0]\n",
        "y_0 = y[l == 0]\n",
        "\n",
        "x_1 = x[l == 1]\n",
        "y_1 = y[l == 1]\n",
        "\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# plt.scatter(x_0, y_0,alpha=0.5,s=30, c='b')\n",
        "# plt.scatter(x_1, y_1,alpha=0.5,s=39, c='r')\n",
        "# plt.title('Training Data',fontsize=18)\n",
        "# plt.show()\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.051267  -0.092742  -0.21371   -0.375     -0.51325   -0.52477\n",
            " -0.39804   -0.30588    0.016705   0.13191    0.38537    0.52938\n",
            "  0.63882    0.73675    0.54666    0.322      0.16647   -0.046659\n",
            " -0.17339   -0.47869   -0.60541   -0.62846   -0.59389   -0.42108\n",
            " -0.11578    0.20104    0.46601    0.67339   -0.13882   -0.29435\n",
            " -0.26555   -0.16187   -0.17339   -0.28283   -0.36348   -0.30012\n",
            " -0.23675   -0.06394    0.062788   0.22984    0.2932     0.48329\n",
            "  0.64459    0.46025    0.6273     0.57546    0.72523    0.22408\n",
            "  0.44297    0.322      0.13767   -0.0063364 -0.092742  -0.20795\n",
            " -0.20795   -0.43836   -0.21947   -0.13882    0.18376    0.22408\n",
            "  0.29896    0.50634    0.61578    0.60426    0.76555    0.92684\n",
            "  0.82316    0.96141    0.93836    0.86348    0.89804    0.85196\n",
            "  0.82892    0.79435    0.59274    0.51786    0.46601    0.35081\n",
            "  0.28744    0.085829   0.14919   -0.13306   -0.40956   -0.39228\n",
            " -0.74366   -0.69758   -0.75518   -0.69758   -0.4038    -0.38076\n",
            " -0.50749   -0.54781    0.10311    0.057028  -0.10426   -0.081221\n",
            "  0.28744    0.39689    0.63882    0.82316    0.67339    1.0709\n",
            " -0.046659  -0.23675   -0.15035   -0.49021   -0.46717   -0.28859\n",
            " -0.61118   -0.66302   -0.59965   -0.72638   -0.83007   -0.72062\n",
            " -0.59389   -0.48445   -0.0063364  0.63265  ]\n",
            "[ 0.69956   0.68494   0.69225   0.50219   0.46564   0.2098    0.034357\n",
            " -0.19225  -0.40424  -0.51389  -0.56506  -0.5212   -0.24342  -0.18494\n",
            "  0.48757   0.5826    0.53874   0.81652   0.69956   0.63377   0.59722\n",
            "  0.33406   0.005117 -0.27266  -0.39693  -0.60161  -0.53582  -0.53582\n",
            "  0.54605   0.77997   0.96272   0.8019    0.64839   0.47295   0.31213\n",
            "  0.027047 -0.21418  -0.18494  -0.16301  -0.41155  -0.2288   -0.18494\n",
            " -0.14108   0.012427  0.15863   0.26827   0.44371   0.52412   0.67032\n",
            "  0.69225   0.57529   0.39985   0.55336   0.35599   0.17325   0.21711\n",
            " -0.016813 -0.27266   0.93348   0.77997   0.61915   0.75804   0.7288\n",
            "  0.59722   0.50219   0.3633    0.27558   0.085526  0.012427 -0.082602\n",
            " -0.20687  -0.36769  -0.5212   -0.55775  -0.7405   -0.5943   -0.41886\n",
            " -0.57968  -0.76974  -0.75512  -0.57968  -0.4481   -0.41155  -0.25804\n",
            " -0.25804   0.041667  0.2902    0.68494   0.70687   0.91886   0.90424\n",
            "  0.70687   0.77997   0.91886   0.99196   1.1089    1.087     0.82383\n",
            "  0.88962   0.66301   0.64108   0.10015  -0.57968  -0.63816  -0.36769\n",
            " -0.3019   -0.13377  -0.060673 -0.067982 -0.21418  -0.41886  -0.082602\n",
            "  0.31213   0.53874   0.49488   0.99927   0.99927  -0.030612]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGL1eQqh3mlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "b00d2443-787d-417a-d312-6a3d7b09877e"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.69956   0.68494   0.69225   0.50219   0.46564   0.2098    0.034357\n",
            " -0.19225  -0.40424  -0.51389  -0.56506  -0.5212   -0.24342  -0.18494\n",
            "  0.48757   0.5826    0.53874   0.81652   0.69956   0.63377   0.59722\n",
            "  0.33406   0.005117 -0.27266  -0.39693  -0.60161  -0.53582  -0.53582\n",
            "  0.54605   0.77997   0.96272   0.8019    0.64839   0.47295   0.31213\n",
            "  0.027047 -0.21418  -0.18494  -0.16301  -0.41155  -0.2288   -0.18494\n",
            " -0.14108   0.012427  0.15863   0.26827   0.44371   0.52412   0.67032\n",
            "  0.69225   0.57529   0.39985   0.55336   0.35599   0.17325   0.21711\n",
            " -0.016813 -0.27266   0.93348   0.77997   0.61915   0.75804   0.7288\n",
            "  0.59722   0.50219   0.3633    0.27558   0.085526  0.012427 -0.082602\n",
            " -0.20687  -0.36769  -0.5212   -0.55775  -0.7405   -0.5943   -0.41886\n",
            " -0.57968  -0.76974  -0.75512  -0.57968  -0.4481   -0.41155  -0.25804\n",
            " -0.25804   0.041667  0.2902    0.68494   0.70687   0.91886   0.90424\n",
            "  0.70687   0.77997   0.91886   0.99196   1.1089    1.087     0.82383\n",
            "  0.88962   0.66301   0.64108   0.10015  -0.57968  -0.63816  -0.36769\n",
            " -0.3019   -0.13377  -0.060673 -0.067982 -0.21418  -0.41886  -0.082602\n",
            "  0.31213   0.53874   0.49488   0.99927   0.99927  -0.030612]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdjlKUr_lstC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "688b3c4c-c5e2-48a0-d3b8-5f97dde1b536"
      },
      "source": [
        "n_data = len(x)              # 데이터 수\n",
        "lter_num = 1000            # 반복 수\n",
        "learning_rate = 0.01         # 러닝레이트\n",
        "\n",
        "def s(z):\n",
        "    return 1 / (1+np.exp(-z))\n",
        "\n",
        "cost_guess = np.array(range(lter_num),dtype=float)           # 변수 저장용 배열 선언\n",
        "training_accuracy = np.array(range(lter_num),dtype=float)\n",
        "\n",
        "W00 = 0.0     # 초기값 설정\n",
        "W01 = 0.0\n",
        "W02 = 0.0\n",
        "W03 = 0.0\n",
        "W04 = 0.0\n",
        "W05 = 0.0\n",
        "W06 = 0.0\n",
        "W07 = 0.0\n",
        "W08 = 0.0\n",
        "W09 = 0.0\n",
        "\n",
        "W10 = 0.0\n",
        "W11 = 0.0\n",
        "W12 = 0.0\n",
        "W13 = 0.0\n",
        "W14 = 0.0\n",
        "W15 = 0.0\n",
        "W16 = 0.0\n",
        "W17 = 0.0\n",
        "W18 = 0.0\n",
        "W19 = 0.0\n",
        "\n",
        "W20 = 0.0\n",
        "W21 = 0.0\n",
        "W22 = 0.0\n",
        "W23 = 0.0\n",
        "W24 = 0.0\n",
        "W25 = 0.0\n",
        "W26 = 0.0\n",
        "W27 = 0.0\n",
        "W28 = 0.0\n",
        "W29 = 0.0\n",
        "\n",
        "W30 = 0.0\n",
        "W31 = 0.0\n",
        "W32 = 0.0\n",
        "W33 = 0.0\n",
        "W34 = 0.0\n",
        "W35 = 0.0\n",
        "W36 = 0.0\n",
        "W37 = 0.0\n",
        "W38 = 0.0\n",
        "W39 = 0.0\n",
        "\n",
        "W40 = 0.0\n",
        "W41 = 0.0\n",
        "W42 = 0.0\n",
        "W43 = 0.0\n",
        "W44 = 0.0\n",
        "W45 = 0.0\n",
        "W46 = 0.0\n",
        "W47 = 0.0\n",
        "W48 = 0.0\n",
        "W49 = 0.0\n",
        "\n",
        "W50 = 0.0\n",
        "W51 = 0.0\n",
        "W52 = 0.0\n",
        "W53 = 0.0\n",
        "W54 = 0.0\n",
        "W55 = 0.0\n",
        "W56 = 0.0\n",
        "W57 = 0.0\n",
        "W58 = 0.0\n",
        "W59 = 0.0\n",
        "\n",
        "W60 = 0.0\n",
        "W61 = 0.0\n",
        "W62 = 0.0\n",
        "W63 = 0.0\n",
        "W64 = 0.0\n",
        "W65 = 0.0\n",
        "W66 = 0.0\n",
        "W67 = 0.0\n",
        "W68 = 0.0\n",
        "W69 = 0.0\n",
        "\n",
        "W70 = 0.0\n",
        "W71 = 0.0\n",
        "W72 = 0.0\n",
        "W73 = 0.0\n",
        "W74 = 0.0\n",
        "W75 = 0.0\n",
        "W76 = 0.0\n",
        "W77 = 0.0\n",
        "W78 = 0.0\n",
        "W79 = 0.0\n",
        "\n",
        "W80 = 0.0\n",
        "W81 = 0.0\n",
        "W82 = 0.0\n",
        "W83 = 0.0\n",
        "W84 = 0.0\n",
        "W85 = 0.0\n",
        "W86 = 0.0\n",
        "W87 = 0.0\n",
        "W88 = 0.0\n",
        "W89 = 0.0\n",
        "\n",
        "W90 = 0.0\n",
        "W91 = 0.0\n",
        "W92 = 0.0\n",
        "W93 = 0.0\n",
        "W94 = 0.0\n",
        "W95 = 0.0\n",
        "W96 = 0.0\n",
        "W97 = 0.0\n",
        "W98 = 0.0\n",
        "W99 = 0.0     # 초기값 설정\n",
        "\n",
        "for i in range(0,lter_num):\n",
        "    z= W00 + W01*y + W02*y*y + W03*y*y*y + W04*y*y*y*y + W05*y*y*y*y*y + W06*y*y*y*y*y*y + W07*y*y*y*y*y*y*y + W08*y*y*y*y*y*y*y*y + W09*y*y*y*y*y*y*y*y*y + W10*x + W11*x*y + W12*x*y*y + W13*x*y*y*y + W14*x*y*y*y*y + W15*x*y*y*y*y*y + W16*x*y*y*y*y*y*y + W17*x*y*y*y*y*y*y*y + W18*x*y*y*y*y*y*y*y*y + W19*x*y*y*y*y*y*y*y*y*y +W20*x*x + W21*x*x*y + W22*x*x*y*y + W23*x*x*y*y*y + W24*x*x*y*y*y*y + W25*x*x*y*y*y*y*y + W26*x*x*y*y*y*y*y*y + W27*x*x*y*y*y*y*y*y*y + W28*x*x*y*y*y*y*y*y*y*y + W29*x*x*y*y*y*y*y*y*y*y*y + W30*x*x*x + W31*x*x*x*y + W32*x*x*x*y*y + W33*x*x*x*y*y*y + W34*x*x*x*y*y*y*y + W35*x*x*x*y*y*y*y*y + W36*x*x*x*y*y*y*y*y*y + W37*x*x*x*y*y*y*y*y*y*y + W38*x*x*x*y*y*y*y*y*y*y*y + W39*x*x*x*y*y*y*y*y*y*y*y*y +W40*x*x*x*x + W41*x*x*x*x*y + W42*x*x*x*x*y*y + W43*x*x*x*x*y*y*y + W44*x*x*x*x*y*y*y*y + W45*x*x*x*x*y*y*y*y*y + W46*x*x*x*x*y*y*y*y*y*y + W47*x*x*x*x*y*y*y*y*y*y*y + W48*x*x*x*x*y*y*y*y*y*y*y*y + W49*x*x*x*x*y*y*y*y*y*y*y*y*y + W50*x*x*x*x*x + W51*x*x*x*x*x*y + W52*x*x*x*x*x*y*y + W53*x*x*x*x*x*y*y*y + W54*x*x*x*x*x*y*y*y*y + W55*x*x*x*x*x*y*y*y*y*y + W56*x*x*x*x*x*y*y*y*y*y*y + W57*x*x*x*x*x*y*y*y*y*y*y*y + W58*x*x*x*x*x*y*y*y*y*y*y*y*y + W59*x*x*x*x*x*y*y*y*y*y*y*y*y*y +W60*x*x*x*x*x*x + W61*x*x*x*x*x*x*y + W62*x*x*x*x*x*x*y*y + W63*x*x*x*x*x*x*y*y*y + W64*x*x*x*x*x*x*y*y*y*y + W65*x*x*x*x*x*x*y*y*y*y*y + W66*x*x*x*x*x*x*y*y*y*y*y*y + W67*x*x*x*x*x*x*y*y*y*y*y*y*y + W68*x*x*x*x*x*x*y*y*y*y*y*y*y*y + W69*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y +W70*x*x*x*x*x*x*x + W71*x*x*x*x*x*x*x*y + W72*x*x*x*x*x*x*x*y*y + W73*x*x*x*x*x*x*x*y*y*y + W74*x*x*x*x*x*x*x*y*y*y*y + W75*x*x*x*x*x*x*x*y*y*y*y*y + W76*x*x*x*x*x*x*x*y*y*y*y*y*y + W77*x*x*x*x*x*x*x*y*y*y*y*y*y*y + W78*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y + W79*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y +W80*x*x*x*x*x*x*x*x + W81*x*x*x*x*x*x*x*x*y + W82*x*x*x*x*x*x*x*x*y*y + W83*x*x*x*x*x*x*x*x*y*y*y + W84*x*x*x*x*x*x*x*x*y*y*y*y + W85*x*x*x*x*x*x*x*x*y*y*y*y*y + W86*x*x*x*x*x*x*x*x*y*y*y*y*y*y + W87*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y + W88*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y + W89*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y +W90*x*x*x*x*x*x*x*x*x + W91*x*x*x*x*x*x*x*x*x*y + W92*x*x*x*x*x*x*x*x*x*y*y + W93*x*x*x*x*x*x*x*x*x*y*y*y + W94*x*x*x*x*x*x*x*x*x*y*y*y*y + W95*x*x*x*x*x*x*x*x*x*y*y*y*y*y + W96*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y + W97*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y + W98*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y + W99*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y\n",
        "   # 예측함수\n",
        "\n",
        "    cost = np.sum(  -l*np.log(s(z)) - (1-l)*np.log(1-s(z))  )/n_data\n",
        "\n",
        "    good = 0\n",
        "    for j in range(0,n_data):\n",
        "        if(z[j]>0):\n",
        "            if(l[j]==1):\n",
        "                good+=1\n",
        "        if(z[j]<0):\n",
        "            if(l[j]==0):\n",
        "                good+=1\n",
        "    training_accuracy[i] = good/n_data       # 정확도 측정\n",
        "\n",
        "    cost_guess[i] = cost                     # 반복마다 값들 저장\n",
        "\n",
        "    gradient_w00 = np.sum((s(z)-l))/n_data\n",
        "    gradient_w01 = np.sum((s(z)-l)*y)/n_data\n",
        "    gradient_w02 = np.sum((s(z)-l)*y*y)/n_data\n",
        "    gradient_w03 = np.sum((s(z)-l)*y*y*y)/n_data\n",
        "    gradient_w04 = np.sum((s(z)-l)*y*y*y*y)/n_data\n",
        "    gradient_w05 = np.sum((s(z)-l)*y*y*y*y*y)/n_data\n",
        "    gradient_w06 = np.sum((s(z)-l)*y*y*y*y*y*y)/n_data\n",
        "    gradient_w07 = np.sum((s(z)-l)*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w08 = np.sum((s(z)-l)*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w09 = np.sum((s(z)-l)*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w10 = np.sum((s(z)-l)*x)/n_data\n",
        "    gradient_w11 = np.sum((s(z)-l)*x*y)/n_data\n",
        "    gradient_w12 = np.sum((s(z)-l)*x*y*y)/n_data\n",
        "    gradient_w13 = np.sum((s(z)-l)*x*y*y*y)/n_data\n",
        "    gradient_w14 = np.sum((s(z)-l)*x*y*y*y*y)/n_data\n",
        "    gradient_w15 = np.sum((s(z)-l)*x*y*y*y*y*y)/n_data\n",
        "    gradient_w16 = np.sum((s(z)-l)*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w17 = np.sum((s(z)-l)*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w18 = np.sum((s(z)-l)*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w19 = np.sum((s(z)-l)*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w20 = np.sum((s(z)-l)*x*x)/n_data\n",
        "    gradient_w21 = np.sum((s(z)-l)*x*x*y)/n_data\n",
        "    gradient_w22 = np.sum((s(z)-l)*x*x*y*y)/n_data\n",
        "    gradient_w23 = np.sum((s(z)-l)*x*x*y*y*y)/n_data\n",
        "    gradient_w24 = np.sum((s(z)-l)*x*x*y*y*y*y)/n_data\n",
        "    gradient_w25 = np.sum((s(z)-l)*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w26 = np.sum((s(z)-l)*x*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w27 = np.sum((s(z)-l)*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w28 = np.sum((s(z)-l)*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w29 = np.sum((s(z)-l)*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w30 = np.sum((s(z)-l)*x*x*x)/n_data\n",
        "    gradient_w31 = np.sum((s(z)-l)*x*x*x*y)/n_data\n",
        "    gradient_w32 = np.sum((s(z)-l)*x*x*x*y*y)/n_data\n",
        "    gradient_w33 = np.sum((s(z)-l)*x*x*x*y*y*y)/n_data\n",
        "    gradient_w34 = np.sum((s(z)-l)*x*x*x*y*y*y*y)/n_data\n",
        "    gradient_w35 = np.sum((s(z)-l)*x*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w36 = np.sum((s(z)-l)*x*x*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w37 = np.sum((s(z)-l)*x*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w38 = np.sum((s(z)-l)*x*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w39 = np.sum((s(z)-l)*x*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w40 = np.sum((s(z)-l)*x*x*x*x)/n_data\n",
        "    gradient_w41 = np.sum((s(z)-l)*x*x*x*x*y)/n_data\n",
        "    gradient_w42 = np.sum((s(z)-l)*x*x*x*x*y*y)/n_data\n",
        "    gradient_w43 = np.sum((s(z)-l)*x*x*x*x*y*y*y)/n_data\n",
        "    gradient_w44 = np.sum((s(z)-l)*x*x*x*x*y*y*y*y)/n_data\n",
        "    gradient_w45 = np.sum((s(z)-l)*x*x*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w46 = np.sum((s(z)-l)*x*x*x*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w47 = np.sum((s(z)-l)*x*x*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w48 = np.sum((s(z)-l)*x*x*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w49 = np.sum((s(z)-l)*x*x*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w50 = np.sum((s(z)-l)*x*x*x*x*x)/n_data\n",
        "    gradient_w51 = np.sum((s(z)-l)*x*x*x*x*x*y)/n_data\n",
        "    gradient_w52 = np.sum((s(z)-l)*x*x*x*x*x*y*y)/n_data\n",
        "    gradient_w53 = np.sum((s(z)-l)*x*x*x*x*x*y*y*y)/n_data\n",
        "    gradient_w54 = np.sum((s(z)-l)*x*x*x*x*x*y*y*y*y)/n_data\n",
        "    gradient_w55 = np.sum((s(z)-l)*x*x*x*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w56 = np.sum((s(z)-l)*x*x*x*x*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w57 = np.sum((s(z)-l)*x*x*x*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w58 = np.sum((s(z)-l)*x*x*x*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w59 = np.sum((s(z)-l)*x*x*x*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w60 = np.sum((s(z)-l)*x*x*x*x*x*x)/n_data\n",
        "    gradient_w61 = np.sum((s(z)-l)*x*x*x*x*x*x*y)/n_data\n",
        "    gradient_w62 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y)/n_data\n",
        "    gradient_w63 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y*y)/n_data\n",
        "    gradient_w64 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y*y*y)/n_data\n",
        "    gradient_w65 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w66 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w67 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w68 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w69 = np.sum((s(z)-l)*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w70 = np.sum((s(z)-l)*x*x*x*x*x*x*x)/n_data\n",
        "    gradient_w71 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y)/n_data\n",
        "    gradient_w72 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y*y)/n_data\n",
        "    gradient_w73 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y*y*y)/n_data\n",
        "    gradient_w74 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y*y*y*y)/n_data\n",
        "    gradient_w75 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w76 = np.sum((s(z)-l*x*x*x*x*x*x*x)*y*y*y*y*y*y)/n_data\n",
        "    gradient_w77 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w78 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w79 = np.sum((s(z)-l)*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w80 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x)/n_data\n",
        "    gradient_w81 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y)/n_data\n",
        "    gradient_w82 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y)/n_data\n",
        "    gradient_w83 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y*y)/n_data\n",
        "    gradient_w84 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y*y*y)/n_data\n",
        "    gradient_w85 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w86 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w87 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w88 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w89 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "    gradient_w90 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x)/n_data\n",
        "    gradient_w91 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y)/n_data\n",
        "    gradient_w92 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y)/n_data\n",
        "    gradient_w93 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y*y)/n_data\n",
        "    gradient_w94 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y*y*y)/n_data\n",
        "    gradient_w95 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y*y*y*y)/n_data\n",
        "    gradient_w96 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y)/n_data\n",
        "    gradient_w97 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w98 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y)/n_data\n",
        "    gradient_w99 = np.sum((s(z)-l)*x*x*x*x*x*x*x*x*x*y*y*y*y*y*y*y*y*y)/n_data\n",
        "\n",
        "\n",
        "    W00 -= learning_rate * gradient_w00\n",
        "    W01 -= learning_rate * gradient_w01\n",
        "    W02 -= learning_rate * gradient_w02\n",
        "    W03 -= learning_rate * gradient_w03\n",
        "    W04 -= learning_rate * gradient_w04\n",
        "    W05 -= learning_rate * gradient_w05\n",
        "    W06 -= learning_rate * gradient_w06\n",
        "    W07 -= learning_rate * gradient_w07\n",
        "    W08 -= learning_rate * gradient_w08\n",
        "    W09 -= learning_rate * gradient_w09\n",
        "\n",
        "    W10 -= learning_rate * gradient_w10\n",
        "    W11 -= learning_rate * gradient_w11\n",
        "    W12 -= learning_rate * gradient_w12\n",
        "    W13 -= learning_rate * gradient_w13\n",
        "    W14 -= learning_rate * gradient_w14\n",
        "    W15 -= learning_rate * gradient_w15\n",
        "    W16 -= learning_rate * gradient_w16\n",
        "    W17 -= learning_rate * gradient_w17\n",
        "    W18 -= learning_rate * gradient_w18\n",
        "    W19 -= learning_rate * gradient_w19\n",
        "\n",
        "    W20 -= learning_rate * gradient_w20\n",
        "    W21 -= learning_rate * gradient_w21\n",
        "    W22 -= learning_rate * gradient_w22\n",
        "    W23 -= learning_rate * gradient_w23\n",
        "    W24 -= learning_rate * gradient_w24\n",
        "    W25 -= learning_rate * gradient_w25\n",
        "    W26 -= learning_rate * gradient_w26\n",
        "    W27 -= learning_rate * gradient_w27\n",
        "    W28 -= learning_rate * gradient_w28\n",
        "    W29 -= learning_rate * gradient_w29\n",
        "\n",
        "    W30 -= learning_rate * gradient_w30\n",
        "    W31 -= learning_rate * gradient_w31\n",
        "    W32 -= learning_rate * gradient_w32\n",
        "    W33 -= learning_rate * gradient_w33\n",
        "    W34 -= learning_rate * gradient_w34\n",
        "    W35 -= learning_rate * gradient_w35\n",
        "    W36 -= learning_rate * gradient_w36\n",
        "    W37 -= learning_rate * gradient_w37\n",
        "    W38 -= learning_rate * gradient_w38\n",
        "    W39 -= learning_rate * gradient_w39\n",
        "\n",
        "    W40 -= learning_rate * gradient_w40\n",
        "    W41 -= learning_rate * gradient_w41\n",
        "    W42 -= learning_rate * gradient_w42\n",
        "    W43 -= learning_rate * gradient_w43\n",
        "    W44 -= learning_rate * gradient_w44\n",
        "    W45 -= learning_rate * gradient_w45\n",
        "    W46 -= learning_rate * gradient_w46\n",
        "    W47 -= learning_rate * gradient_w47\n",
        "    W48 -= learning_rate * gradient_w48\n",
        "    W49 -= learning_rate * gradient_w49\n",
        "\n",
        "    W50 -= learning_rate * gradient_w50\n",
        "    W51 -= learning_rate * gradient_w51\n",
        "    W52 -= learning_rate * gradient_w52\n",
        "    W53 -= learning_rate * gradient_w53\n",
        "    W54 -= learning_rate * gradient_w54\n",
        "    W55 -= learning_rate * gradient_w55\n",
        "    W56 -= learning_rate * gradient_w56\n",
        "    W57 -= learning_rate * gradient_w57\n",
        "    W58 -= learning_rate * gradient_w58\n",
        "    W59 -= learning_rate * gradient_w59\n",
        "\n",
        "    W60 -= learning_rate * gradient_w60\n",
        "    W61 -= learning_rate * gradient_w61\n",
        "    W62 -= learning_rate * gradient_w62\n",
        "    W63 -= learning_rate * gradient_w63\n",
        "    W64 -= learning_rate * gradient_w64\n",
        "    W65 -= learning_rate * gradient_w65\n",
        "    W66 -= learning_rate * gradient_w66\n",
        "    W67 -= learning_rate * gradient_w67\n",
        "    W68 -= learning_rate * gradient_w68\n",
        "    W69 -= learning_rate * gradient_w69\n",
        "\n",
        "    W70 -= learning_rate * gradient_w70\n",
        "    W71 -= learning_rate * gradient_w71\n",
        "    W72 -= learning_rate * gradient_w72\n",
        "    W73 -= learning_rate * gradient_w73\n",
        "    W74 -= learning_rate * gradient_w74\n",
        "    W75 -= learning_rate * gradient_w75\n",
        "    W76 -= learning_rate * gradient_w76\n",
        "    W77 -= learning_rate * gradient_w77\n",
        "    W78 -= learning_rate * gradient_w78\n",
        "    W79 -= learning_rate * gradient_w79\n",
        "\n",
        "    W80 -= learning_rate * gradient_w80\n",
        "    W81 -= learning_rate * gradient_w81\n",
        "    W82 -= learning_rate * gradient_w82\n",
        "    W83 -= learning_rate * gradient_w83\n",
        "    W84 -= learning_rate * gradient_w84\n",
        "    W85 -= learning_rate * gradient_w85\n",
        "    W86 -= learning_rate * gradient_w86\n",
        "    W87 -= learning_rate * gradient_w87\n",
        "    W88 -= learning_rate * gradient_w88\n",
        "    W89 -= learning_rate * gradient_w89\n",
        "\n",
        "    W90 -= learning_rate * gradient_w90\n",
        "    W91 -= learning_rate * gradient_w91\n",
        "    W92 -= learning_rate * gradient_w92\n",
        "    W93 -= learning_rate * gradient_w93\n",
        "    W94 -= learning_rate * gradient_w94\n",
        "    W95 -= learning_rate * gradient_w95\n",
        "    W96 -= learning_rate * gradient_w96\n",
        "    W97 -= learning_rate * gradient_w97\n",
        "    W98 -= learning_rate * gradient_w98\n",
        "    W99 -= learning_rate * gradient_w99\n",
        "\n",
        "\n",
        "# print(W1,W2,W3,W4,W5,b)  # 학습 후 W1,W2,W3,b 값 확인\n",
        "print(cost)  # 학습 후 cost값 확인\n",
        "print(good/n_data)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6119277593654766\n",
            "0.7288135593220338\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}